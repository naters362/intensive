{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<include type=\"image\">\n",
    "\n",
    "###### This is not a pipe\n",
    "    \n",
    "![](../img/cecinestpas.jpg)\n",
    "\n",
    "</include>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So far, we've established a general workflow where we:\n",
    "\n",
    "\n",
    "1. **Clean the data Fill/impute/drop `NaN` values**\n",
    "   - One-hot encode categorical variables\n",
    "   - Label-encode target if categorical\n",
    "   - Check for skew / deskew\n",
    "\n",
    "1. **Preprocess the data**\n",
    "   - Feature selection (`SelectKBest, SelectFromModel, SelectPercentile, RFE`, etc.)\n",
    "   - Scaling (`StandardScaler, MinMaxScaler`)\n",
    "\n",
    "1. **Modeling**\n",
    "   - Classification (`KNeighborsClassifier, LogisticRegression`, etc.)\n",
    "   - Regression (`Lasso, Ridge, ElasticNet`, etc.)\n",
    "  \n",
    "For every dataset, we've done some version of all of these. Pipelines give us a convenient way to chain these tasks together. As a result, we can feed cleaned data into a pipeline and a trained model a the end!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Import the Python Numerical Stack\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Load bike sharing data\n",
    "\n",
    "bike_data = pd.read_csv('data/bike_sharing.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  season  holiday  workingday  temp\n",
       "0  2011-01-01 00:00:00       1        0           0  9.84\n",
       "1  2011-01-01 01:00:00       1        0           0  9.02\n",
       "2  2011-01-01 02:00:00       1        0           0  9.02\n",
       "3  2011-01-01 03:00:00       1        0           0  9.84\n",
       "4  2011-01-01 04:00:00       1        0           0  9.84"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Display a few columns from the head of `DataFrame`\n",
    "\n",
    "bike_data[['datetime', 'season', 'holiday', 'workingday', 'temp']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Convert the datetime colum to datetime using pd.to_datetime()\n",
    "\n",
    "bike_data['datetime'] = pd.to_datetime(bike_data['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Make a feature for the day of week\n",
    "\n",
    "bike_data['dayofweek'] = bike_data['datetime'].apply(lambda x: x.dayofweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Make a feature for month\n",
    "\n",
    "bike_data['month'] = bike_data['datetime'].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Make a feature for hour\n",
    "\n",
    "bike_data['hour'] = bike_data['datetime'].apply(lambda x: x.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Drop the datetime column\n",
    "\n",
    "bike_data.drop('datetime', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Split up our features and target into features and target\n",
    "\n",
    "features = bike_data.drop('count',axis=1)\n",
    "\n",
    "target = bike_data['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Get dummies of categorical columns\n",
    "\n",
    "num_cols = ['temp','atemp','humidity','windspeed']\n",
    "cat_cols = [i for i in features.columns if i not in num_cols]\n",
    "\n",
    "features_dummies = pd.get_dummies(features, columns=cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pipeline` is a class in `sklearn` that allows us to chain steps together. \n",
    "\n",
    "We add steps to the pipeline using a list of tuples of the form `[('step name', sklearn object)...]`\n",
    "\n",
    "Let's make a `Pipeline` that scales the data and fits a `RandomForestRegressor` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Load necessary classes and functions from Scikit-Learn \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import (StandardScaler, \n",
    "                                   MinMaxScaler)\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Train-test split your data\n",
    "\n",
    "split_data = train_test_split(\n",
    "    features_dummies, \n",
    "    target, \n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Instantiate your pipeline\n",
    "\n",
    "simple_pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()), \n",
    "    ('lasso', Lasso())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Fit the pipeline to your training features and target\n",
    "\n",
    "simple_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6388499611022919"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### What's your train r2 score?\n",
    "\n",
    "simple_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6274260376321519"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### What's your test r2 score?\n",
    "\n",
    "simple_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a fit `Pipeline` object that scores just like any other model. This consists of a `StandardScaler` and a `Lasso`. What properties does this `Pipeline` have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `.steps` gives you a list of tuples containing the names of your steps and the fit object of the step itself.\n",
    "- `.named_steps` gives you a dictionary with your pipeline objects where the keys are the names and the values are the fit sklearn object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       " ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "     normalize=False, positive=False, precompute=False, random_state=None,\n",
       "     selection='cyclic', tol=0.0001, warm_start=False))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Look at the steps\n",
    "\n",
    "simple_pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'lasso': Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "    normalize=False, positive=False, precompute=False, random_state=None,\n",
       "    selection='cyclic', tol=0.0001, warm_start=False)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Look at the named steps\n",
    "\n",
    "simple_pipe.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access each step and use it if we'd like. Let's look at the mean and standard deviation of our data from the scaler object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.02449804e+01, 2.36701605e+01, 6.18351298e+01, 1.27913341e+01,\n",
       "       2.45835375e-01, 2.51224890e-01, 2.49755022e-01, 2.53184713e-01,\n",
       "       9.70602646e-01, 2.93973542e-02, 3.16756492e-01, 6.83243508e-01,\n",
       "       6.62175404e-01, 2.60289074e-01, 7.74130328e-02, 1.22488976e-04,\n",
       "       1.41474767e-01, 1.42822146e-01, 1.43312102e-01, 1.43434591e-01,\n",
       "       1.41597256e-01, 1.44169525e-01, 1.43189613e-01, 7.96178344e-02,\n",
       "       8.30475257e-02, 8.31700147e-02, 8.14551690e-02, 8.56197942e-02,\n",
       "       8.41499265e-02, 8.31700147e-02, 8.47623714e-02, 8.18226360e-02,\n",
       "       8.51298383e-02, 8.51298383e-02, 8.29250367e-02, 4.28711416e-02,\n",
       "       4.10338070e-02, 4.22586967e-02, 4.00538951e-02, 4.12787849e-02,\n",
       "       4.20137188e-02, 4.16462518e-02, 4.12787849e-02, 4.21362077e-02,\n",
       "       4.12787849e-02, 4.18912298e-02, 4.06663400e-02, 4.11562959e-02,\n",
       "       4.04213621e-02, 4.10338070e-02, 4.22586967e-02, 4.18912298e-02,\n",
       "       4.31161195e-02, 4.37285644e-02, 4.17687408e-02, 4.15237629e-02,\n",
       "       4.02988731e-02, 4.14012739e-02, 4.29936306e-02])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Display means from `StandardScaler`\n",
    "\n",
    "simple_pipe.steps[0][1].mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.79554011e+00, 8.46820631e+00, 1.92546121e+01, 8.21341117e+00,\n",
       "       4.30581401e-01, 4.33717586e-01, 4.32871171e-01, 4.34835848e-01,\n",
       "       1.68917583e-01, 1.68917583e-01, 4.65211583e-01, 4.65211583e-01,\n",
       "       4.72968433e-01, 4.38792288e-01, 2.67245683e-01, 1.10667959e-02,\n",
       "       3.48510628e-01, 3.49891384e-01, 3.50390844e-01, 3.50515490e-01,\n",
       "       3.48636592e-01, 3.51261545e-01, 3.50266110e-01, 2.70700637e-01,\n",
       "       2.75954044e-01, 2.76139029e-01, 2.73532858e-01, 2.79801796e-01,\n",
       "       2.77612529e-01, 2.76139029e-01, 2.78527758e-01, 2.74094313e-01,\n",
       "       2.79074809e-01, 2.79074809e-01, 2.75768880e-01, 2.02566549e-01,\n",
       "       1.98368429e-01, 2.01178774e-01, 1.96085646e-01, 1.98934278e-01,\n",
       "       2.00620453e-01, 1.99779482e-01, 1.98934278e-01, 2.00899845e-01,\n",
       "       1.98934278e-01, 2.00340597e-01, 1.97516047e-01, 1.98651593e-01,\n",
       "       1.96945362e-01, 1.98368429e-01, 2.01178774e-01, 2.00340597e-01,\n",
       "       2.03118487e-01, 2.04490531e-01, 2.00060274e-01, 1.99498220e-01,\n",
       "       1.96659284e-01, 1.99216486e-01, 2.02842743e-01])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### .std_ is deprecated, use .scale_\n",
    "\n",
    "simple_pipe.named_steps['scaler'].scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 37.81956127,  15.07856264, -20.97367854,  -4.80325321,\n",
       "        -8.67445325,   0.        ,  -0.        ,  16.55810977,\n",
       "         0.        ,  -0.        ,  -0.        ,   0.        ,\n",
       "         1.69301497,  -0.        , -13.9527773 ,  -0.16920321,\n",
       "        -0.97024358,  -0.45100847,   0.        ,   0.        ,\n",
       "         0.24940573,   1.67373388,  -3.22686251,  -3.55528056,\n",
       "        -0.        ,   0.        ,  -0.        ,   5.86413596,\n",
       "         0.        ,  -7.73988209,  -3.77614438,   3.19136327,\n",
       "         1.1122235 ,   0.        ,   0.        , -27.62730192,\n",
       "       -30.25156015, -31.97763363, -33.90388915, -33.8726006 ,\n",
       "       -31.07937045, -18.90032333,   4.83038122,  34.76910242,\n",
       "         3.98765501,  -6.1951688 ,  -1.00767564,   3.73829618,\n",
       "         3.83990337,   0.        ,   1.67571803,  13.79605162,\n",
       "        44.87442287,  41.18548178,  19.23742649,   2.42356056,\n",
       "        -6.19354438, -12.34345661, -20.45458108])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Display $\\beta_i$ for Lasso Model\n",
    "\n",
    "simple_pipe.named_steps['lasso'].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  The `make_pipeline`  helper function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `Pipeline` gives us the ability to explicitly name our steps, this can be cumbersome, especially when we may not care what are steps are named. If this is the case, we use `make_pipeline`.\n",
    "\n",
    "Let's execute the same pipeline, except this time we'll use `make_pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Import `make_pipeline` helper function \n",
    "\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Define a second `Pipeline` using `make_pipeline`\n",
    "\n",
    "another_pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    Lasso()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Fit second `Pipeline`\n",
    "\n",
    "another_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6388499611022919"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Display training score\n",
    "\n",
    "another_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6274260376321519"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Display testing score\n",
    "\n",
    "another_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we don't name them, `make_pipeline` still has a `.named_steps` attribute. It automatically assigns names to each step and we can access them similarly to how we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'lasso': Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "    normalize=False, positive=False, precompute=False, random_state=None,\n",
       "    selection='cyclic', tol=0.0001, warm_start=False)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Display named steps for `Pipeline`\n",
    "\n",
    "another_pipe.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       " ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "     normalize=False, positive=False, precompute=False, random_state=None,\n",
       "     selection='cyclic', tol=0.0001, warm_start=False))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Display steps for `Pipeline`\n",
    "\n",
    "another_pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aside: Transformation pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it's standard to have a pipeline end in a model, it's also possible to have a pipeline just for transformers, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Import transformers from Scikit-Learn \n",
    "\n",
    "from sklearn.feature_selection import (SelectFromModel, \n",
    "                                       SelectKBest, \n",
    "                                       f_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Make transformation pipeline\n",
    "\n",
    "transformer_pipe = make_pipeline(\n",
    "    SelectKBest(score_func=f_regression, k=40),\n",
    "    StandardScaler(),\n",
    "    SelectFromModel(Lasso())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('selectkbest', SelectKBest(k=40, score_func=<function f_regression at 0x1167a8158>)), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('selectfrommodel', SelectFromModel(estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "        norm_order=1, prefit=False, threshold=None))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Fit transformation pipeline\n",
    "\n",
    "transformer_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Use transformation pipeline to transform data\n",
    "\n",
    "features_skb_scaled_sfm = transformer_pipe.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8164, 59)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Show shape of training set\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8164, 36)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Show shape of transformed data\n",
    "\n",
    "features_skb_scaled_sfm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('selectkbest',\n",
       "  SelectKBest(k=40, score_func=<function f_regression at 0x1167a8158>)),\n",
       " ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       " ('selectfrommodel',\n",
       "  SelectFromModel(estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "     normalize=False, positive=False, precompute=False, random_state=None,\n",
       "     selection='cyclic', tol=0.0001, warm_start=False),\n",
       "          norm_order=1, prefit=False, threshold=None))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Show steps in transformation pipeline\n",
    "\n",
    "transformer_pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Make transformation pipeline\n",
    "\n",
    "transformer_pipe = make_pipeline(\n",
    "    SelectKBest(score_func=f_regression, k=40),\n",
    "    FunctionTransformer(lambda x: x + 1),\n",
    "    FunctionTransformer(np.log),    \n",
    "    StandardScaler(),\n",
    "    SelectFromModel(Lasso())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('selectkbest', SelectKBest(k=40, score_func=<function f_regression at 0x1167a8158>)), ('functiontransformer-1', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function <lambda> at 0x1167e0840>, inv_kw_args=None,\n",
       "          inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "      ...ction='cyclic', tol=0.0001, warm_start=False),\n",
       "        norm_order=1, prefit=False, threshold=None))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Pipelines with `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've only chained transformers and models together in a `pipeline`. What if we want to use GridSearch to tune our model in the `pipeline`?\n",
    "\n",
    "Since we have to refer to our steps by name, let's use `Pipeline` instead of `make_pipeline`. \n",
    "\n",
    "Let's make a pipeline with the following steps:\n",
    "\n",
    "    ('skb', SelectKBest(score_func=f_regression, k=40)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('sfm', SelectFromModel(Lasso())),\n",
    "    ('regr', ElasticNet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Load necessary models\n",
    "\n",
    "from sklearn.model_selection import (GridSearchCV, \n",
    "                                     ShuffleSplit)\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Create model pipeline\n",
    "\n",
    "pipe_for_gs = Pipeline([\n",
    "    ('skb', SelectKBest(score_func=f_regression, k=40)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('sfm', SelectFromModel(Lasso())),\n",
    "    ('regr', ElasticNet())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('skb', SelectKBest(k=40, score_func=<function f_regression at 0x1167a8158>)),\n",
       " ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       " ('sfm',\n",
       "  SelectFromModel(estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "     normalize=False, positive=False, precompute=False, random_state=None,\n",
       "     selection='cyclic', tol=0.0001, warm_start=False),\n",
       "          norm_order=1, prefit=False, threshold=None)),\n",
       " ('regr', ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_for_gs.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's make our parameter grid. When using a `Pipeline`, we need to specify which step our params are for. To do that, we use the name we gave the step (in this case `'rf'` for `RandomForestRegressor`), with a **dunder** to reference a parameter for that model. \n",
    "\n",
    "As an example, if we wanted to tune `ElasticNet`'s `l1_ratio` parameter, we use `regr__l1_ratio:[.1,.5,.9]`. \n",
    "\n",
    "Let's fill out the params below to tune `alpha` and `l1_ratio`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Define parameter grid\n",
    "\n",
    "params = {\n",
    "    'regr__l1_ratio':[.1,.3,.5,.7,.9],\n",
    "    'regr__alpha':np.logspace(-3,3,7)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now pass your pipeline into `GridSearchCV` with your parameters, using `ShuffleSplit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Create grid search model pipeline\n",
    "\n",
    "gspipe = GridSearchCV(\n",
    "    pipe_for_gs, \n",
    "    param_grid=params, \n",
    "    cv=ShuffleSplit(n_splits=5, random_state=42), \n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=5, random_state=42, test_size='default',\n",
       "       train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('skb', SelectKBest(k=40, score_func=<function f_regression at 0x1167a8158>)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('sfm', SelectFromModel(estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precomput...alse, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'regr__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9], 'regr__alpha': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Fit the grid search model pipeline\n",
    "\n",
    "gspipe.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6441703040776783"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Display best score for grid search model pipeline\n",
    "\n",
    "gspipe.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the `.steps` or `.named_steps`, we need to access `GridSearchCV`'s `.best_estimator_` parameter, which contains our `Pipeline`. How do we access our model? Our scaler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'skb': SelectKBest(k=40, score_func=<function f_regression at 0x1167a8158>),\n",
       " 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'sfm': SelectFromModel(estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "    normalize=False, positive=False, precompute=False, random_state=None,\n",
       "    selection='cyclic', tol=0.0001, warm_start=False),\n",
       "         norm_order=1, prefit=False, threshold=None),\n",
       " 'regr': ElasticNet(alpha=0.001, copy_X=True, fit_intercept=True, l1_ratio=0.9,\n",
       "       max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "       random_state=None, selection='cyclic', tol=0.0001, warm_start=False)}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Display named steps for best estimator\n",
    "\n",
    "gspipe.best_estimator_.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Display regression model\n",
    "\n",
    "best_enet = gspipe.best_estimator_.named_steps['regr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 39.92653743,  10.10050404, -19.59674176,  -6.9950194 ,\n",
       "        -7.23595587,  17.10287993,   2.74715023, -14.92393049,\n",
       "        -5.73295031,  -1.57377095,   7.71882526,   2.13610853,\n",
       "        -7.04904951,  -3.25638783,   5.10841142,   2.36382364,\n",
       "       -26.11055493, -28.89860596, -30.62160723, -32.66509316,\n",
       "       -32.59217767, -29.80127324, -17.64190498,  38.11542642,\n",
       "         7.53283836,   7.71971398,   7.85236345,   4.14529761,\n",
       "         5.98572129,  18.02889019,  49.07576023,  45.28690045,\n",
       "        23.15600355,   6.06896904, -10.67302863, -18.89872011])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_enet.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "        norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Display `SelectFromModel` transformer\n",
    "\n",
    "gspipe.best_estimator_.named_steps['sfm']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
